<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>计算机视觉基础实验</title>
    <link href="/2022/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/"/>
    <url>/2022/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<p>本文实现了基础的图像预处理、图像增强、图像分割和图像检索</p><span id="more"></span><h1 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h1><p><a href="#%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86">图像处理</a><br /><a href="#%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2">图像检索</a></p><hr /><h2 id="图像处理"><a class="markdownIt-Anchor" href="#图像处理"></a> 图像处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br>im=Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>im_L = im.convert(<span class="hljs-string">&quot;L&quot;</span>) <br>box = (<span class="hljs-number">560</span>,<span class="hljs-number">1000</span>,<span class="hljs-number">1800</span>,<span class="hljs-number">1800</span>)<br>region = im_L.crop(box)<br>region.save(<span class="hljs-string">&quot;d:\\3.jpg&quot;</span>) <span class="hljs-comment">#region是一个新的图像对象</span><br>region.show()<br>im1 = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data\\1.jpg&quot;</span>)<br>im2 = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data\\2.jpg&quot;</span>)<br>r1,g1,b1 = im1.split()<br>r2,g2,b2 = im2.split()<br><span class="hljs-comment">#print(r1.mode,r1.size,g1.mode,g1.size)</span><br><span class="hljs-comment">#print(r2.mode,r2.size,g2.mode,g2.size)</span><br>new_im=[r1,g2,b2]<br><span class="hljs-comment">#print(len(new_im))</span><br>im_merge = Image.merge(<span class="hljs-string">&quot;RGB&quot;</span>,new_im)<br>im_merge.show()<br></code></pre></td></tr></table></figure><ul><li>image = image.convert()是图像实例对象的一个方法，接受一个mode参数，用以指定一个色彩模式 L：8位像素，黑白</li><li>Image.crop(left，up，right，below)对图片进行切割</li><li>Image.split()方法用于将图像分成单独的波段。此方法从图像返回单个图像带的元组。分割“RGB”图像会创建三个新图像，每个图像都包含一个原始波段(红色，绿色，蓝色)的副本。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> *<br><span class="hljs-comment"># 读取图像到数组中</span><br>im = array(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&#x27;</span>))<br><span class="hljs-comment"># 绘制图像</span><br>imshow(im)<br><span class="hljs-comment"># 一些点</span><br>x = [<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">400</span>,<span class="hljs-number">400</span>]<br>y = [<span class="hljs-number">200</span>,<span class="hljs-number">500</span>,<span class="hljs-number">200</span>,<span class="hljs-number">500</span>]<br><span class="hljs-comment"># 使用红色星状标记绘制点</span><br>plot(x,y,<span class="hljs-string">&#x27;r*&#x27;</span>)<br><span class="hljs-comment"># 绘制连接前两个点的线</span><br>plot(x[:<span class="hljs-number">2</span>],y[:<span class="hljs-number">2</span>])<br><span class="hljs-comment"># 添加标题，显示绘制的图像</span><br>title(<span class="hljs-string">&#x27;Plotting: &quot;empire.jpg&quot;&#x27;</span>)<br>show()<br></code></pre></td></tr></table></figure><p><img src="https://s1.imagehub.cc/images/2022/09/02/outpvut.png" alt="" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageEnhance<br><span class="hljs-comment">#原始图像</span><br>image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>image.show()<br><span class="hljs-comment">#亮度增强</span><br>enh_bri = ImageEnhance.Brightness(image) <br>brightness = <span class="hljs-number">1.5</span><br>image_brightened = enh_bri.enhance(brightness) <br>image_brightened.show()<br></code></pre></td></tr></table></figure><ul><li>ImageEnhance.Brightness(image)创建一个调整图像亮度的增强对象</li><li>enhance()的参数brightness决定着图像的亮度情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#对比度增强</span><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageEnhance<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageFilter<br><span class="hljs-comment">#原始图像</span><br>image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>image.show()<br><span class="hljs-comment">#对比度增强</span><br>enh_con = ImageEnhance.Contrast(image)<br>contrast = <span class="hljs-number">1.5</span><br>image_contrasted = enh_con.enhance(contrast)<br>image_contrasted.show()<br><span class="hljs-comment">#锐度增强</span><br>enh_sha = ImageEnhance.Sharpness(image)<br>sharpness = <span class="hljs-number">3.0</span><br>image_sharped = enh_sha.enhance(sharpness)<br>image_sharped.show()<br><span class="hljs-comment">#图像模糊</span><br>im = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>im_blur = im.<span class="hljs-built_in">filter</span>(ImageFilter.BLUR)<br>im_blur.show()<br><span class="hljs-comment">#轮廓提取</span><br>im = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>im_contour = im.<span class="hljs-built_in">filter</span>(ImageFilter.CONTOUR)<br>im_contour.show()<br><span class="hljs-comment">#细节增强</span><br>im = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;</span>)<br>im_contour = im.<span class="hljs-built_in">filter</span>(ImageFilter.DETAIL)<br>im_contour.show()<br></code></pre></td></tr></table></figure><ul><li>ImageFilter.BLUR为模糊滤波，处理之后的图像会整体变得模糊。</li><li>ImageFilter.CONTOUR为轮廓滤波，将图像中的轮廓信息全部提取出来。</li><li>ImageFilter.DETAIL为细节增强滤波，会使得图像中细节更加明显。<br /><img src="https://s1.imagehub.cc/images/2022/09/02/Snipaste_2022-09-02_11-53-50.png" alt="" /></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#画直方图</span><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>img=np.array(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data//1.jpg&quot;</span>).convert(<span class="hljs-string">&#x27;L&#x27;</span>))<br>plt.figure(<span class="hljs-string">&quot;lena&quot;</span>) <span class="hljs-comment">#对灰度图像(lena)进行处理</span><br>arr=img.flatten() <span class="hljs-comment">#返回一个一维数组</span><br>n, bins, patches = plt.hist(arr, bins=<span class="hljs-number">256</span>, color=<span class="hljs-string">&#x27;green&#x27;</span>, alpha=<span class="hljs-number">0.75</span>)<br><span class="hljs-comment">#绘制直方图</span><br>plt.show()<br></code></pre></td></tr></table></figure><ul><li>bins: 直方图的柱数，即要分的组数</li><li>normed: 是否将得到的直方图向量归一化，即显示占比</li><li>alpha: 透明度<br /><img src="https://s1.imagehub.cc/images/2022/09/02/outprut.png" alt="" /></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#图像分割</span><br><span class="hljs-comment"># 图片二值化</span><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br>img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&#x27;</span>)<br><span class="hljs-comment"># 模式 L”为灰色图像，它的每个像素用 8 个 bit 表示，0 表示黑，255 表示白，其他数字表示不同的灰度。</span><br>Img = img.convert(<span class="hljs-string">&#x27;L&#x27;</span>)<br><span class="hljs-comment">#Img.save(&quot;C:\\Users\\86156\\Desktop\\备用图床\\0494e945880511ebb6edd017c2d2eca2.png&quot;)</span><br><span class="hljs-comment"># 自定义灰度界限，大于这个值为黑色，小于这个值为白色</span><br>threshold = <span class="hljs-number">100</span> <span class="hljs-comment">#灰度界限</span><br>table = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>):<br>    <span class="hljs-keyword">if</span> i &lt; threshold:<br>        table.append(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>:<br>        table.append(<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 图片二值化</span><br>photo = Img.point(table, <span class="hljs-string">&#x27;1&#x27;</span>) <span class="hljs-comment">#将table转换成图像</span><br>photo.show()<br></code></pre></td></tr></table></figure><p><img src="https://s1.imagehub.cc/images/2022/09/02/Snipaste_2022-09-02_11-56-36.png" alt="" /></p><hr /><h2 id="图像检索"><a class="markdownIt-Anchor" href="#图像检索"></a> 图像检索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> scipy<br><span class="hljs-keyword">import</span> scipy.spatial<br><span class="hljs-keyword">from</span> cv2 <span class="hljs-keyword">import</span> imread<br><span class="hljs-keyword">import</span> pickle <br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib.image <span class="hljs-keyword">as</span> mpimg<br><span class="hljs-comment"># 特征提取</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_features</span>(<span class="hljs-params">image_path, vector_size=<span class="hljs-number">32</span></span>):<br>    image = imread(image_path)<span class="hljs-comment">#imread函数从文件中加载图像并返回该图像</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-comment"># 可选的特征检测算法有 BRISK,AKAZE,KAZE 以及 ORB</span><br>        <span class="hljs-comment"># 关键点检测</span><br>        alg = cv2.BRISK_create() <span class="hljs-comment">#特征检测算法</span><br>        <span class="hljs-comment"># alg = cv2.AKAZE_create()</span><br>        <span class="hljs-comment"># alg = cv2.KAZE_create()</span><br>        <span class="hljs-comment"># alg = cv2.ORB_create()</span><br>        kps = alg.detect(image) <span class="hljs-comment">#提取image的特征</span><br>        <span class="hljs-comment"># 选取前 vector_size=32 个特征点</span><br>        <span class="hljs-comment"># 特征点的个数取决于图像的大小以及颜色分布</span><br>        <span class="hljs-comment"># 按照关键点响应值对特征点进行排序</span><br>        kps = <span class="hljs-built_in">sorted</span>(kps, key=<span class="hljs-keyword">lambda</span> x: -x.response)[:vector_size]<br>        <span class="hljs-comment"># 计算特征点上对应的特征向量</span><br>        kps, dsc = alg.compute(image, kps)<br>        <span class="hljs-comment"># 将所有的特征向量组成一个大的特征值</span><br>        dsc = dsc.flatten()<br>        <span class="hljs-comment"># 预定义一个维度为 64*vector_size 的特征向量</span><br>        needed_size = (vector_size * <span class="hljs-number">64</span>)<br>        <span class="hljs-keyword">if</span> dsc.size &lt; needed_size:<br>            <span class="hljs-comment"># 如果计算得到的特征向量小于预定义的大小，则在向量末尾补零</span><br>            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])<br>    <span class="hljs-keyword">except</span> cv2.error <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Error: &#x27;</span>, e)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">return</span> dsc<br></code></pre></td></tr></table></figure><p>特征提取函数，输入想要提取的图片的路径(image_path)，提取该图片的特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_extractor</span>(<span class="hljs-params">images_path, pickled_db_path=<span class="hljs-string">&quot;data/feature.txt&quot;</span></span>):<br>    files = [os.path.join(images_path, p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(os.listdir(images_path))]<br>    result = &#123;&#125;<br>    <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> files:<br>        <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Extracting features from image %s&#x27;</span> % f)<br>        name = f.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].lower()<br>        result[name] = extract_features(f)<br><span class="hljs-comment"># 将所有特征保存在 pickle 文件里</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(pickled_db_path, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> fp: <span class="hljs-comment"># 以二进制写入</span><br>        pickle.dump(result, fp)<br></code></pre></td></tr></table></figure><p>在pickled_db_path路径建立一个文件，输入的image_path为一个文件夹，文件夹中为想要对比的几张图片，依次将图片的信息写入文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Matcher</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pickled_db_path=<span class="hljs-string">&quot;data/feature.txt&quot;</span></span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(pickled_db_path,<span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> fp:<br>            self.data = pickle.load(fp) <span class="hljs-comment">#用于将二进制对象文件转换成 Python 对象</span><br>        self.names = []<br>        self.matrix = []<br>        <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.data.items():<br>            self.names.append(k)<br>            self.matrix.append(v)<br>        self.matrix = np.array(self.matrix)<br>        self.names = np.array(self.names)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cdist</span>(<span class="hljs-params">self, vector</span>):<br>    <span class="hljs-comment"># 计算图像之间的 cosine 距离</span><br>        v = vector.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> scipy.spatial.distance.cdist(self.matrix, v, <span class="hljs-string">&#x27;cosine&#x27;</span>).reshape(-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">match</span>(<span class="hljs-params">self, image_path, topn=<span class="hljs-number">5</span></span>):<br>        features = extract_features(image_path)<br>        img_distances = self.cdist(features)<br>        <span class="hljs-comment"># 找到排名前 5 的匹配结果</span><br>        nearest_ids = np.argsort(img_distances)[:topn].tolist()<br>        nearest_img_paths = self.names[nearest_ids].tolist()<br>        <span class="hljs-keyword">return</span> nearest_img_paths, img_distances[nearest_ids].tolist() <span class="hljs-comment">#tolist将矩阵转换成列表</span><br></code></pre></td></tr></table></figure><p>定义一个类Matcher，在类中实现函数：cdist()计算cosine距离；match()找到和image_path这张图最相似的topn张图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">show_img</span>(<span class="hljs-params">path</span>):<br>    img = mpimg.imread(path)<br>    plt.imshow(img)<br>    plt.show()<br></code></pre></td></tr></table></figure><p>将图片输出的函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>():<br>    images_path = <span class="hljs-string">&#x27;data//images&#x27;</span> <br>    files = [os. path.join(images_path, p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(os.listdir(images_path))]<br>    <span class="hljs-comment"># 打乱数据库中的图像顺序</span><br>    sample = random.sample(files, <span class="hljs-number">3</span>)<br>    batch_extractor(images_path)<br>    ma = Matcher(<span class="hljs-string">&#x27;data/feature.txt&#x27;</span>)<br>    <span class="hljs-comment"># 查询图像名称</span><br>    s = <span class="hljs-string">&#x27;data/2.jpg&#x27;</span> <br>    <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Query image ==========================================&#x27;</span>)<br>    show_img(s)<br>    names, <span class="hljs-keyword">match</span> = ma.<span class="hljs-keyword">match</span>(s, topn=<span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Result images ========================================&#x27;</span> )<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    <span class="hljs-comment"># 计算 cosine 距离，将相似性定义为 1-cosine 距离，当两个图像越近，此值相似指越高</span><br>        <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Match %s&#x27;</span> % (<span class="hljs-number">1</span>-<span class="hljs-keyword">match</span>[i]))<br>        show_img(os.path.join(<span class="hljs-string">&#x27;data//&#x27;</span>, names[i]))<br>run() <span class="hljs-comment">#运行从这里开始</span><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><p>Extracting features from image data//images\1000.png<br />Extracting features from image data//images\1001.png<br />Extracting features from image data//images\1002.png<br />Extracting features from image data//images\1003.png<br />Extracting features from image data//images\1004.png<br />Extracting features from image data//images\1007.png<br />Extracting features from image data//images\1008.png<br />Extracting features from image data//images\1009.png<br />Extracting features from image data//images\1010.png<br />Query image ==========================================<br /><img src="https://s1.imagehub.cc/images/2022/09/02/outpubt.png" alt="" /><br />Result images ========================================<br />Match 0.7166246434214855<br /><img src="https://s1.imagehub.cc/images/2022/09/02/outpgut.png" alt="" /><br />Match 0.7156440097021429<br /><img src="https://s1.imagehub.cc/images/2022/09/02/outptut.png" alt="" /><br />Match 0.7029691317235767<br /><img src="https://s1.imagehub.cc/images/2022/09/02/outpunt.png" alt="" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>CV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Disentangled Self-Attentive Neural Networks for Click-Through Rate Prediction》论文笔记</title>
    <link href="/2022/09/01/%E3%80%8ADisentangled-Self-Attentive-Neural-Networks-for-Click-Through-Rate-Prediction%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/09/01/%E3%80%8ADisentangled-Self-Attentive-Neural-Networks-for-Click-Through-Rate-Prediction%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1><p>CTR是一个排序模型，CTR预测的数据具有稀疏性和高维的特点。对于排序模型而言，特征交叉很关键</p><p>FM通过为特征分配latent factors实现特征自动交叉<br />W&amp;D框架在DNN的基础上引入Wide模型学习显式特征交叉<br />FM 通常只适合学习低阶（2-order）交叉特征，W&amp;D 框架的 wide 部分与 LR 类似，需要人工设计交叉特征，工作量较大。DeepFM 在 W&amp;D 框架基础上，将其 wide 部分替换为能自动抽取低阶交叉特征的 FM 组件，避免了特征工程且能端到端训练</p><p>建立高阶特征交互模型是进行有效预测的关键，通过自注意神经网络(self-attention)对特征向量进行点积计算，是一种有效方式，但点积是在两个特征之间进行，忽视了单个特征域(field)的影响，针对上述问题，论文提出 DESTINE结构，将一元(unary)特征重要性计算，从二阶特征交叉(pairwise interaction)解耦出来：一元项学习单个特征相对其他特征的重要度，二阶交叉项单纯地学习每个特征对的影响。</p><p>高阶特征交互建模的一个广泛使用的解决方案是计算特征嵌入的内积(inner product),每个特征对之间的点积注意力分数(the dot-product attention scores)可以被认为是每个特征对的重要性，为了建立任意顺序的特征交互模型，可以堆叠多层带残差连接（residual connections）的自注意网络<br />也就是说这个模型分为两部分，一部分是特征嵌入向量的点积，包含着每对特征的关系；一部分是一元特征模型，将一元项（unary term）从自注意网络中解耦（decouple），代表一个特征与其他所有特征的关系。</p>]]></content>
    
    
    
    <tags>
      
      <tag>CTR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络基础实验</title>
    <link href="/2022/08/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/"/>
    <url>/2022/08/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<p>本文介绍了基于numpy的回归神经网络,以及基于pytorch的回归神经网络和分类神经网络</p><span id="more"></span><h1 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h1><p><a href="#%E5%9F%BA%E4%BA%8Enumpy%E7%9A%84%E5%9B%9E%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">基于numpy的回归神经网络</a><br /><a href="#%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84%E5%9B%9E%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">基于pytorch的回归神经网络</a><br /><a href="#%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84%E5%88%86%E7%B1%BB%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">基于pytorch的分类神经网络</a></p><hr /><h2 id="基于numpy的回归神经网络"><a class="markdownIt-Anchor" href="#基于numpy的回归神经网络"></a> 基于numpy的回归神经网络</h2><p><strong>实验目的</strong><br />1.了解反向传播网络的基本原理；<br />2.了解梯度下降法进行神经网络中的权值更新；<br />3.学习使用 numpy 编写简单的三层回归网络进行回归实验。<br /><strong>实验内容</strong><br />使用 numpy 库构建简单的数据集，编写简单的三层回归神经网络，输入和输出只有一个神经元，中间隐藏层可设置 N 个神经元，采用 sigmoid 函数作为激活函数。数据集按 y=x+随机噪声进行构建，x 取值为 0, 1, …, 19。学习梯度计算，及梯度下降法进行神经网络的权值修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid_derivative</span>(<span class="hljs-params">s</span>):  <span class="hljs-comment">#对sigmoid进行求导</span><br>    ds = s*(<span class="hljs-number">1</span>-s)<br>    <span class="hljs-keyword">return</span> ds<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):   <br>    s=<span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(-x))<br>    <span class="hljs-keyword">return</span> s<br></code></pre></td></tr></table></figure><ul><li>激活函数sigmoid函数也叫Logistic函数，是一个在生物学上常见的S型函数,用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。Sigmoid作为激活函数有以下优缺点：</li><li><ul><li>优点：平滑、易于求导。</li></ul></li><li><ul><li>缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法；反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。<br /><img src="https://s1.imagehub.cc/images/2022/08/31/Snipaste_2022-08-31_17-34-12.png" alt="" /></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">N,D_in,H,D_out = <span class="hljs-number">20</span>,<span class="hljs-number">1</span>,<span class="hljs-number">64</span>,<span class="hljs-number">1</span><br>np.random.seed(<span class="hljs-number">0</span>)<br>x=np.arange(<span class="hljs-number">0</span>,N,<span class="hljs-number">1</span>).reshape(N,D_in)*<span class="hljs-number">1.0</span><br>y=x+np.random.randn(N,D_out)<br></code></pre></td></tr></table></figure><p>生成随机数据,x为一个[20,1]的从0-19数据,y为随机的[1,20]的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">w1=np.random.randn(D_in,H)<br>w2=np.random.randn(H,D_out)<br></code></pre></td></tr></table></figure><p>随机生成两个参数w1,w2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">learning_rate=<span class="hljs-number">1e-4</span> <span class="hljs-comment">#学习率</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20000</span>): <span class="hljs-comment">#反向传播算法</span><br>    y1=x.dot(w1) <span class="hljs-comment">#x和w1进行点积 得到y1  20*64 第一层</span><br>    y_relu=sigmoid(y1) <span class="hljs-comment">#将y1输入激活函数得到f(y1) 20*64</span><br>    y2=y_relu.dot(w2) <span class="hljs-comment">#f(y)和w2进行点积得到y2  20*1 第二层</span><br>    loss=np.square(y2-y).<span class="hljs-built_in">sum</span>() <span class="hljs-comment">#损失函数</span><br>    grad_y2=<span class="hljs-number">2.0</span>*(y2-y) <span class="hljs-comment">#损失函数对y2的偏导数 20*1</span><br>    grad_w2=y_relu.T.dot(grad_y2) <span class="hljs-comment"># 损失函数对w2的偏导数 y_relu的转置(64*20)与grad_y2(20*1)的点积 (64*1)</span><br>    grad_y1=grad_y2.dot(w2.T) <br>    grad_y1=grad_y1*sigmoid_derivative(y_relu)<br>    grad_w1=x.T.dot(grad_y1) <span class="hljs-comment">#损失函数对w1的偏导数</span><br>    w1-=learning_rate*grad_w1<br>    w2-=learning_rate*grad_w2<br>    <span class="hljs-keyword">if</span>(t%<span class="hljs-number">2000</span>==<span class="hljs-number">0</span>):<br>        plt.cla()<br>        plt.scatter(x,y)<br>        plt.scatter(x,y2)<br>        plt.plot(x,y2,<span class="hljs-string">&#x27;r-&#x27;</span>,lw=<span class="hljs-number">1</span>,label=<span class="hljs-string">&quot;plot figure&quot;</span>)<br>        plt.text(<span class="hljs-number">0.5</span>,<span class="hljs-number">0</span>,<span class="hljs-string">&#x27;t=%d:Loss=%.4f&#x27;</span>%(t,loss),fontdict=&#123;<span class="hljs-string">&#x27;size&#x27;</span>:<span class="hljs-number">20</span>,<span class="hljs-string">&#x27;color&#x27;</span>:<span class="hljs-string">&#x27;red&#x27;</span>&#125;)<br>        plt.show()<br></code></pre></td></tr></table></figure><p>用反向传播算法得到<strong>w1和w2的梯度</strong>,再根据学习率对w1和w2进行适当的更新</p><ul><li><strong>反向传播算法:</strong> 简称BP算法，适合于多层神经元网络的一种学习算法，它建立在<strong>梯度下降法</strong>的基础上。BP算法的学习过程由正向传播过程和反向传播过程组成。在正向传播过程中，输入信息通过输入层经隐含层，逐层处理并传向输出层。如果在输出层得不到期望的输出值，则取输出与期望的误差的平方和作为目标函数，转入反向传播，逐层求出目标函数对各神经元权值的偏导数，构成目标函数对权值向量的梯量，作为修改权值的依据，网络的学习在权值修改过程中完成。误差达到所期望值时，网络学习结束。</li><li><strong>梯度下降法:</strong> 绝大多数的机器学习模型都会有一个损失函数。比如常见的均方误差（Mean Squared Error)损失函数,梯度下降的目的，就是为了<strong>最小化损失函数</strong>。根据损失函数对w1和w2求导得到的梯度,我们知道该往梯度方向更新参数来减小损失函数:<br /><img src="https://s1.imagehub.cc/images/2022/08/31/Snipaste_2022-08-31_18-50-01.png" alt="" /><br />但是更新不宜过多,也不宜过少,过多会直接越过最小值,过小会使学习效率过低,这里我们用到学习率(Learning Rate)这个概念。通过学习率，可以计算前进的距离。</li></ul><p>代码运行结果如下:<br /><img src="https://s1.imagehub.cc/images/2022/08/31/out1put.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/ou2tput.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/out3put.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/outpu4t.png" alt="" /></p><hr /><h2 id="基于pytorch的回归神经网络"><a class="markdownIt-Anchor" href="#基于pytorch的回归神经网络"></a> 基于pytorch的回归神经网络</h2><p>上面我们看到基于numpy实现的回归神经网络,但如果修改学习率,很大概率会梯度消失,难以拟合.而pytorch封装的函数对模型的训练效果会更好.</p><p><strong>实验目的：</strong></p><ol><li>了解 pytorch 下采用 adam 梯度下降法进行神经网络中的权值更新；</li><li>学习使用 pytorch 编写简单的三层神经网络进行回归实验。</li></ol><p><strong>实验内容：</strong><br />使用 numpy 库构建简单的数据集，编写简单的三层回归神经网络，输入和输出只有一个神经元，中间隐藏层可设置 N 个神经元，采用 Sigmoid 函数作为激活函数。数据集按 y=x+随机噪声进行构建，x 取值为 0, 1, …, 19。了解 pytorch 中的梯度计算，及梯度下降法进行神经网络的权值更新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>N, D_in, H, D_out = <span class="hljs-number">50</span>, <span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">1</span><br>np.random.seed(<span class="hljs-number">0</span>)<br>x = torch.tensor(np.arange(<span class="hljs-number">0</span>,N,<span class="hljs-number">1</span>).reshape(N,D_in),dtype=torch.float32) <br>y = x +torch.tensor(np.random.randn(N,D_out), dtype=torch.float32)<br></code></pre></td></tr></table></figure><p>生成训练集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.nn.Sequential(<br>torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), )<span class="hljs-comment">#构建模型 两层全连接层</span><br></code></pre></td></tr></table></figure><ul><li>torch.nn.Sequential是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。通俗的话说，就是根据自己的需求，把不同的函数组合成一个（小的）模块使用或者把组合的模块添加到自己的网络中。</li><li>PyTorch的nn.Linear（）用于设置神经网络中的全连接层。</li><li>此处用的激活函数是ReLU。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_fn = torch.nn.MSELoss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>) <span class="hljs-comment">#损失函数</span><br></code></pre></td></tr></table></figure><ul><li>torch.nn.MSELoss()用于测量输入x和目标y中每个元素之间的均方误差。reduction为’sum’表示求和,'mean’表示求平均</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">learning_rate = <span class="hljs-number">1e-4</span> <span class="hljs-comment">#学习率</span><br>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) <span class="hljs-comment">#优化器：优化参数 model.parameters()传入参数</span><br></code></pre></td></tr></table></figure><ul><li>model.parameters()保存的是Weights和Bais参数的值。</li><li>torch.optim是一个实现了多种优化算法的包，大多数通用的方法都已支持，提供了丰富的接口调用，未来更多精炼的优化算法也将整合进来。<br />为了使用torch.optim，需先构造一个优化器对象Optimizer，用来保存当前的状态，并能够根据计算得到的梯度来更新参数。</li><li>Adam(Adaptive Moment Estimation)本质上是带有动量项的RMSprop，它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。它的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5000</span>):<br>    y_pred = model(x)<br>    loss = loss_fn(y_pred, y)<br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>        plt.cla()<br>        plt.scatter(x.data.numpy(),y.data.numpy())<br>        plt.scatter(x.data.numpy(),y_pred.data.numpy())<br>        plt.plot(x.data.numpy(),y_pred.data.numpy(),<span class="hljs-string">&#x27;r-&#x27;</span>,lw=<span class="hljs-number">1</span>, label=<span class="hljs-string">&quot;plot figure&quot;</span>)<br>        plt.text(<span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;t=%d:Loss=%.4f&#x27;</span> % (t, loss), fontdict=&#123;<span class="hljs-string">&#x27;size&#x27;</span>: <span class="hljs-number">20</span>, <span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;red&#x27;</span>&#125;)<br>        plt.show()<br>    optimizer.zero_grad() <span class="hljs-comment">#清空过往梯度</span><br>    loss.backward() <span class="hljs-comment">#反向传播，计算当前梯度</span><br>    optimizer.step() <span class="hljs-comment"># 根据梯度更新网络参数</span><br></code></pre></td></tr></table></figure><p>计算预估的y值y_pred,求出损失值,计算梯度,由此更新参数,反复训练,得到结果:<br /><img src="https://s1.imagehub.cc/images/2022/08/31/1output.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/2output.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/3output.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/4output.png" alt="" /></p><hr /><h2 id="基于pytorch的分类神经网络"><a class="markdownIt-Anchor" href="#基于pytorch的分类神经网络"></a> 基于pytorch的分类神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>n_data = torch.ones(<span class="hljs-number">100</span>, <span class="hljs-number">2</span>) <span class="hljs-comment">#生成一个全为1的矩阵</span><br>x0 = torch.normal(<span class="hljs-number">2</span>*n_data, <span class="hljs-number">1</span>) <span class="hljs-comment"># class0 x data (tensor), shape=(100, 2)</span><br>y0 = torch.zeros(<span class="hljs-number">100</span>) <span class="hljs-comment"># class0 y data (tensor), shape=(100, 1)</span><br>x1 = torch.normal(-<span class="hljs-number">2</span>*n_data, <span class="hljs-number">1</span>) <span class="hljs-comment"># class1 x data (tensor), shape=(100, 2)</span><br>y1 = torch.ones(<span class="hljs-number">100</span>) <span class="hljs-comment"># class1 y data (tensor), shape=(100, 1)</span><br>x = torch.cat((x0, x1), <span class="hljs-number">0</span>).<span class="hljs-built_in">type</span>(torch.FloatTensor) <span class="hljs-comment"># shape (200, 2) FloatTensor = 32-bit floating</span><br>y = torch.cat((y0, y1), ).<span class="hljs-built_in">type</span>(torch.LongTensor) <span class="hljs-comment"># shape (200,) LongTensor = 64-bit integer</span><br></code></pre></td></tr></table></figure><p>生成训练样本</p><ul><li>torch.ones()生成一个全为1的矩阵</li><li>torch.normal(means, std, out=None)</li><li><ul><li>means (Tensor)均值 std (Tensor)标准差 out (Tensor)可选的输出张量</li></ul></li><li>torch.cat()在给定维度上对输入的张量序列进行连接操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_feature, n_hidden, n_output</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.hidden = torch.nn.Linear(n_feature, n_hidden) <span class="hljs-comment"># hidden layer</span><br>        self.out = torch.nn.Linear(n_hidden, n_output) <span class="hljs-comment"># output layer</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = torch.sigmoid(self.hidden(x)) <span class="hljs-comment"># activation function for hidden layer</span><br>        x = self.out(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><ul><li>在定义自已的网络的时候，需要继承nn.Module类，并重新实现构造函数__init__构造函数和forward这两个方法。</li><li>super().<strong>init</strong>()，就是继承父类的init方法，同样可以使用super()去继承其他方法。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">net = Net(n_feature=<span class="hljs-number">2</span>, n_hidden=<span class="hljs-number">10</span>, n_output=<span class="hljs-number">2</span>) <span class="hljs-comment"># define the network</span><br>optimizer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.02</span>) <br>loss_func = torch.nn.CrossEntropyLoss()<br>plt.ion()<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    out = net(x) <span class="hljs-comment"># 预测的值</span><br>    loss = loss_func(out, y) <span class="hljs-comment"># 计算损失</span><br>    optimizer.zero_grad() <span class="hljs-comment"># 清空梯度</span><br>    loss.backward() <span class="hljs-comment"># 反向传播</span><br>    optimizer.step() <span class="hljs-comment"># 更新梯度</span><br>    <span class="hljs-keyword">if</span> t % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>        plt.cla()<br>        prediction = torch.<span class="hljs-built_in">max</span>(out, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]<br>        pred_y = prediction.data.numpy()<br>        target_y = y.data.numpy()<br>        plt.scatter(x.data.numpy()[:, <span class="hljs-number">0</span>], x.data.numpy()[:, <span class="hljs-number">1</span>], c=pred_y, s=<span class="hljs-number">100</span>, lw=<span class="hljs-number">0</span>, cmap=<span class="hljs-string">&#x27;RdYlGn&#x27;</span>)<br>        accuracy = <span class="hljs-built_in">float</span>((pred_y == target_y).astype(<span class="hljs-built_in">int</span>).<span class="hljs-built_in">sum</span>()) / <span class="hljs-built_in">float</span>(target_y.size)<br>        plt.text(<span class="hljs-number">1.5</span>, -<span class="hljs-number">4</span>, <span class="hljs-string">&#x27;Accuracy=%.2f&#x27;</span> % accuracy, fontdict=&#123;<span class="hljs-string">&#x27;size&#x27;</span>: <span class="hljs-number">20</span>, <span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;red&#x27;</span>&#125;)<br>        plt.pause(<span class="hljs-number">0.1</span>)<br>plt.ioff()<br>plt.show()<br></code></pre></td></tr></table></figure><p>运行结果如下:<br /><img src="https://s1.imagehub.cc/images/2022/08/31/outputq.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/outpzut.png" alt="" /><br /><img src="https://s1.imagehub.cc/images/2022/08/31/outxput.png" alt="" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>人工智能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习基础实验</title>
    <link href="/2022/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/"/>
    <url>/2022/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<p>本文介绍了监督学习和无监督学习的经典算法：线性回归以及k-means聚类算法。</p><span id="more"></span><h1 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h1><p><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">线性回归（监督学习）</a><br /><a href="#k-means%E8%81%9A%E7%B1%BB%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">k-means聚类（无监督学习）</a></p><hr /><h1 id="线性回归监督学习"><a class="markdownIt-Anchor" href="#线性回归监督学习"></a> 线性回归（监督学习）</h1><p><strong>实验目的：</strong></p><p>1.了解线性回归的基本原理<br />2.掌握通过梯度下降方法实现最优解的求解</p><p><strong>实验环境：</strong> python，sklearn，numpy</p><p><strong>实验步骤：</strong></p><p>1、生成数据<br />2、定义画图函数、假设函数、损失函数、梯度计算函数、参数更新函数<br />3、定义线性回归函数，并测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># %matplotlib inline</span><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_regression <span class="hljs-comment">#导入 make_regression()函数，用来生成回归</span><br>模型数据<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt <span class="hljs-comment">#导入 matplotlib.pyplot，并且重命名为 plt</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <span class="hljs-comment">#导入 numpy 库，并且重命名为 np</span><br></code></pre></td></tr></table></figure><ul><li>函数 make_regression()：用来生成回归模型数据</li><li>参数说明：<br />n_samples：样本数<br />n_features：特征数<br />noise：噪音<br />bias：偏差</li><li>X : array of shape [n_samples, n_features]<br />y : array of shape [n_samples] or [n_samples, n_targets]</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">X, y= make_regression(n_samples=<span class="hljs-number">100</span>, n_features=<span class="hljs-number">1</span>, noise=<span class="hljs-number">0.4</span>, bias=<span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure><p>定义一个名为 plotLine()的函数，用来画出生成数据集的散点图和拟合线性模型(y=k*x+b)</p><ul><li><p>参数说明：<br />theta0:即 y=k<em>x+b 中的参数 b<br />theta1:即 y=k</em>x+b 中的参数 k<br />X:数据集的横坐标（列表类型）<br />y:数据集的纵坐标（列表类型）</p></li><li><p>np.linspace(start, stop, num)函数：用来返回 num 个等间距的样本，在区间[start, stop]中。</p></li><li><p>plt.plot(x,y,color,label)：可视化函数<br />参数说明：color:用来设置线条的颜色，color='r’表示红色(b 表示蓝色)；label 用于指定标签</p></li><li><p>plt.scatter(x,y)：用来画散点图。</p></li><li><p>plt.axis(）函数用来指定坐标轴的范围。<br />参数需要以列表的形式给出。</p></li><li><p>plt.show()：将图像显示出。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plotLine</span>(<span class="hljs-params">theta0, theta1, X, y</span>):<br>    max_x = np.<span class="hljs-built_in">max</span>(X) + <span class="hljs-number">100</span> <span class="hljs-comment">#np.max(X)用来取出 X 中的最大值</span><br>    min_x = np.<span class="hljs-built_in">min</span>(X) - <span class="hljs-number">100</span> <span class="hljs-comment">#np.min(X)用来取出 X 中的最小值</span><br>    xplot = np.linspace(min_x, max_x, <span class="hljs-number">1000</span>) <span class="hljs-comment">#在区间[min_x,max_x]中返回 1000 个等间隔的样本</span><br>    yplot = theta0 + theta1 * xplot <span class="hljs-comment">#将 x 带入线性方程 y=k*x+b 中求得 y</span><br>    <span class="hljs-built_in">print</span>(theta0) <span class="hljs-comment">#打印参数 theta0</span><br>    <span class="hljs-built_in">print</span>(theta1) <span class="hljs-comment">#打印参数 theta1</span><br>    plt.plot(xplot, yplot, color=<span class="hljs-string">&#x27;g&#x27;</span>, label=<span class="hljs-string">&#x27;Regression Line&#x27;</span>) <span class="hljs-comment">#画出线性模型，参数依次表示：横坐标，纵坐标，颜色，标签</span><br>    plt.scatter(X,y) <span class="hljs-comment">#画散点图，参数依次表示横坐标、纵坐标</span><br>    plt.axis([-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>, <span class="hljs-number">200</span>]) <span class="hljs-comment">#设置横坐标范围为【-10，10】，纵轴范围为【0，200】</span><br>    plt.show() <span class="hljs-comment">#显示可视化图像</span><br></code></pre></td></tr></table></figure><p>定义一个函数返回y的估计值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">hypothesis</span>(<span class="hljs-params">theta0, theta1, x</span>):<br>    <span class="hljs-keyword">return</span> theta0 + (theta1 * x)<br></code></pre></td></tr></table></figure><p>定义损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">theta0, theta1, X, y</span>):  <span class="hljs-comment"># 计算损失</span><br>    costValue = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> (xi, yi) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(X, y):  <span class="hljs-comment"># 使用 zip()函数，包为元组的列表</span><br>        costValue += <span class="hljs-number">0.5</span> * ((hypothesis(theta0, theta1, xi) - yi) ** <span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> costValue<br></code></pre></td></tr></table></figure><p>定义名为 derivatives()的函数，用来计算参数的梯度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">derivatives</span>(<span class="hljs-params">theta0, theta1, X, y</span>): <span class="hljs-comment">#derivative:导数</span><br>    dtheta0 = <span class="hljs-number">0</span> <span class="hljs-comment">#dtheta0：参数 theta0 的梯度，初始化为 0</span><br>    dtheta1 = <span class="hljs-number">0</span> <span class="hljs-comment">#dtheta0：参数 theta0 的梯度，初始化为 0</span><br>    <span class="hljs-keyword">for</span> (xi, yi) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(X, y): <span class="hljs-comment">#使用 zip()函数依次取出(xi,yi)</span><br>        dtheta0 += hypothesis(theta0, theta1, xi) - yi<br>        dtheta1 += (hypothesis(theta0, theta1, xi) - yi)*xi <span class="hljs-comment">#计算公式为：损失函数对参数</span><br>    dtheta0 /= <span class="hljs-built_in">len</span>(X) <span class="hljs-comment">#求平均梯度，len(X)函数用来计算 X 中的样本数</span><br>    dtheta1 /= <span class="hljs-built_in">len</span>(X) <span class="hljs-comment">#求平均梯度</span><br>    <span class="hljs-keyword">return</span> dtheta0,dtheta1<br></code></pre></td></tr></table></figure><p>定义一个名为 updateParameters()的函数，用来对参数进行更新:</p><ul><li>参数说明：<br />theta0 和 theta1 为待更新参数。<br />X、 y 分别表示横轴和纵轴的数值。<br />alpha：学习率。</li><li>参数的更新：<br />对于参数 w，其更新方式为：w=w-学习率*梯度值。其中学习率是一个超参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">updateParameters</span>(<span class="hljs-params">theta0, theta1, X, y, alpha</span>):  <span class="hljs-comment"># 参数的更新，alpha 表示学习率</span><br>    dtheta0, dtheta1 = derivatives(theta0, theta1, X, y)  <span class="hljs-comment"># dtheta0, dtheta1 分 别 表 示 参 数</span><br>    theta0 = theta0 - (alpha * dtheta0)  <span class="hljs-comment"># 依据参数更新方式更新参数 theta0</span><br>    theta1 = theta1 - (alpha * dtheta1)  <span class="hljs-comment"># 依据参数更新方式更新参数 theta1</span><br>    <span class="hljs-keyword">return</span> theta0, theta1  <span class="hljs-comment"># 返回更新好的参数</span><br></code></pre></td></tr></table></figure><p>定义并调用一个名为 LinearRegression()的线性回归函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">LinearRegression</span>(<span class="hljs-params">X, y</span>):<br>    theta0 = np.random.rand()  <span class="hljs-comment"># 给 theta0 赋一个随机初始值。</span><br>    theta1 = np.random.rand()  <span class="hljs-comment"># 给 theta1 赋一个随机初始值。</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1000</span>):  <span class="hljs-comment"># 进行 1000 次参数的更新，每隔 100 次跟新打印一次图片</span><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:  <span class="hljs-comment"># 只有当 i 整除 100 时才进行一次图片打印</span><br>            plotLine(theta0, theta1, X, y)<br>            <span class="hljs-built_in">print</span>(cost(theta0, theta1, X, y))<br>        theta0, theta1 = updateParameters(theta0, theta1, X, y, <span class="hljs-number">0.005</span>)<br>LinearRegression(X, y) <span class="hljs-comment">#调用线性回归函数。</span><br></code></pre></td></tr></table></figure><p>实验结果如下：</p><h2 id="g1g2g3g4g5g6g7"><a class="markdownIt-Anchor" href="#g1g2g3g4g5g6g7"></a> <img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-27-30.png" alt="g1" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-27-52.png" alt="g2" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-28-21.png" alt="g3" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-28-35.png" alt="g4" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-28-42.png" alt="g5" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-28-54.png" alt="g6" /><br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-29-06.png" alt="g7" /></h2><p><strong>原理</strong><br />给定一组样本观测值x<sub>i</sub>,y<sub>i</sub>，(i=1,2,…n)，要求回归函数尽可能拟合这组值。普通最小二乘法给出的判断标准是：残差平方和的值达到最小。<br />残差平方和的公式为：<br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-43-27.png" alt="g8" /><br />有两个未知参数的二次方程，画出来是一个三维空间中的图像，类似下面：<br /><img src="https://s1.imagehub.cc/images/2022/08/30/Snipaste_2022-08-30_18-43-38.png" alt="g9" /><br />导数为0时，Q取最小值，因此我们分别对\beta<sub>1</sub>和\beta<sub>2</sub>求偏导并令其为0。</p><h1 id="k-means聚类无监督学习"><a class="markdownIt-Anchor" href="#k-means聚类无监督学习"></a> k-means聚类（无监督学习）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br></code></pre></td></tr></table></figure><p>定义一个名为 euclDistance()的函数，用来计算两个矩阵之间的欧式距离。其中参数vector1, vector2 分别表示两个矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">euclDistance</span>(<span class="hljs-params">vector1, vector2</span>):<br>    <span class="hljs-keyword">return</span> sqrt(<span class="hljs-built_in">sum</span>(power(vector2 - vector1, <span class="hljs-number">2</span>))) <span class="hljs-comment">#求这两个矩阵的距离，vector1、2 均为矩阵</span><br></code></pre></td></tr></table></figure><p>定义一个名为 initCentroids()的函数，用来在样本集中随机选取 k 个样本点作为初始<br />质心，其中参数 dataSet 为已给数据集，k 表示创建中心点的个数。返回值为所创建的 k 个中心点</p><ul><li>np.zeros([k, n])：用来创建一个 k 行 n 列的全 0 数组。</li><li>np.random.uniform(a,b):返回区间[a,b)中的任意值。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#在样本集中随机选取 k 个样本点作为初始质心。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initCentroids</span>(<span class="hljs-params">dataSet, k</span>):<br>    numSamples, dim = dataSet.shape <span class="hljs-comment">#矩阵的行数、列数 。</span><br>    centroids = zeros((k, dim)) <span class="hljs-comment"># 创建一个 k 行 dim 列的全 0 数组。</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        index = <span class="hljs-built_in">int</span>(random.uniform(<span class="hljs-number">0</span>, numSamples)) <span class="hljs-comment">#随机产生一个浮点数，然后将其转化为 int 型。</span><br>        centroids[i, :] = dataSet[index, :] <span class="hljs-comment"># 将 dataSet 中 第 index+1 行 赋 值 给centroids 的第 i+1 行。</span><br>    <span class="hljs-keyword">return</span> centroids<br></code></pre></td></tr></table></figure><p>定义一个名为 kmeans()的聚类算法，用于将 dataSet 矩阵中的样本分成 k 个类</p><ul><li>np.mat(a):用于将数组 a 转换为矩阵。</li><li>np.zeros([k, n])：用来创建一个 k 行 n 列的全 0 数组。</li><li>matrix.A:将矩阵类型转换为 array 类型。</li><li>np.nonzero(array):用于得到数组 array 中非零元素的位置（数组索引）,参数 array 为<br />一个数组。</li><li>np.mean()：求均值。</li><li>plt.plot(x,y,color,marksize):当使用此函数画一个数据点时，参数 x 表示横坐标,参数 y 表示纵坐标，参数 color 用来指定点的颜色，参数 marksize 用来指示点的大小。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">kmeans</span>(<span class="hljs-params">dataSet, k</span>):<br>    numSamples = dataSet.shape[<span class="hljs-number">0</span>] <span class="hljs-comment">#读取矩阵 dataSet 的第一维度的长度,即获得有多少个样本数据</span><br>    clusterAssment = mat(zeros((numSamples, <span class="hljs-number">2</span>))) <span class="hljs-comment">#得到一个 N*2 的零矩阵,建立簇分配结果矩阵，第一列存类别，第二列存误差。</span><br>    clusterChanged = <span class="hljs-literal">True</span> <span class="hljs-comment">#用来判断样本聚类结果是否变化的变量。</span><br>    <span class="hljs-comment">## step 1: init centroids</span><br>    centroids = initCentroids(dataSet, k) <span class="hljs-comment">#在样本集中随机选取 k 个样本点作为初始质心</span><br>    <span class="hljs-keyword">while</span> clusterChanged:<br>        clusterChanged = <span class="hljs-literal">False</span><br>        <span class="hljs-comment">## for each sample</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numSamples): <span class="hljs-comment">#range</span><br>            minDist = <span class="hljs-number">100000.0</span> <span class="hljs-comment">#创建的一个临时变量，用来储存某个样本到所有聚类中心的最小距离。</span><br>            minIndex = <span class="hljs-number">0</span> <span class="hljs-comment">#创建的一个临时变量，用来储存和某个样本距离最近的聚类中心的类别作为该样本的类别。</span><br>            <span class="hljs-comment">## for each centroid</span><br>            <span class="hljs-comment">## step 2: find the centroid who is closest</span><br>            <span class="hljs-comment">#计算每个样本点与质点之间的距离，将其归内到距离最小的那一簇</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>                distance = euclDistance(centroids[j, :], dataSet[i, :]) <span class="hljs-comment">#计算每个样本到每个聚类中心之间的距离。</span><br>                <span class="hljs-keyword">if</span> distance &lt; minDist:<br>                    minDist = distance<br>                    minIndex = j<br>            <span class="hljs-comment">## step 3: update its cluster</span><br>            <span class="hljs-comment">#k 个簇里面与第 i 个样本距离最小的的标号和距离保存在 clusterAssment中</span><br>            <span class="hljs-comment">#若所有的样本所属类别不在变化，则退出 while 循环</span><br>            <span class="hljs-keyword">if</span> clusterAssment[i, <span class="hljs-number">0</span>] != minIndex:<br>                clusterChanged = <span class="hljs-literal">True</span><br>                clusterAssment[i, :] = minIndex, minDist**<span class="hljs-number">2</span> <span class="hljs-comment">#两个**表示的是 minDist的平方</span><br>        <span class="hljs-comment">## step 4: update centroids</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>            <span class="hljs-comment">#clusterAssment[:,0].A==j 是找出矩阵 clusterAssment 中第一列元素中等于j 的行的下标，返回的是一个以 array 的列表，第一个 array 为等于 j 的下标</span><br>            pointsInCluster = dataSet[nonzero(clusterAssment[:, <span class="hljs-number">0</span>].A == j)[<span class="hljs-number">0</span>]] <span class="hljs-comment">#将 dataSet矩阵中相对应的样本提取出来</span><br>            centroids[j, :] = mean(pointsInCluster, axis = <span class="hljs-number">0</span>) <span class="hljs-comment">#计算标注为 j 的所有样本的平均值</span><br>    <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Congratulations, cluster complete!&#x27;</span>)<br>    <span class="hljs-keyword">return</span> centroids, clusterAssment<br><span class="hljs-comment"># show your cluster only available with 2-D data</span><br><span class="hljs-comment">#centroids 为 k 个类别，其中保存着每个类别的质心</span><br><span class="hljs-comment">#clusterAssment 为样本的标记，第一列为此样本的类别号，第二列为到此类别质心的距离</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">showCluster</span>(<span class="hljs-params">dataSet, k, centroids, clusterAssment</span>):<br>    numSamples, dim = dataSet.shape<br>    <span class="hljs-keyword">if</span> dim != <span class="hljs-number">2</span>:<br>        <span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;Sorry! I can not draw because the dimension of your data is not 2!&quot;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    mark = [<span class="hljs-string">&#x27;or&#x27;</span>, <span class="hljs-string">&#x27;ob&#x27;</span>, <span class="hljs-string">&#x27;og&#x27;</span>, <span class="hljs-string">&#x27;ok&#x27;</span>, <span class="hljs-string">&#x27;^r&#x27;</span>, <span class="hljs-string">&#x27;+r&#x27;</span>, <span class="hljs-string">&#x27;sr&#x27;</span>, <span class="hljs-string">&#x27;dr&#x27;</span>, <span class="hljs-string">&#x27;&lt;r&#x27;</span>, <span class="hljs-string">&#x27;pr&#x27;</span>] <span class="hljs-comment">#样本颜色</span><br>    <span class="hljs-keyword">if</span> k &gt; <span class="hljs-built_in">len</span>(mark):<br>        <span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;Sorry! Your k is too large! please contact wojiushimogui&quot;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-comment"># draw all samples</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numSamples):<br>        markIndex = <span class="hljs-built_in">int</span>(clusterAssment[i, <span class="hljs-number">0</span>]) <span class="hljs-comment">#为样本指定颜色</span><br>        plt.plot(dataSet[i, <span class="hljs-number">0</span>], dataSet[i, <span class="hljs-number">1</span>], mark[markIndex]) <span class="hljs-comment">#画出样本</span><br>    mark = [<span class="hljs-string">&#x27;Dr&#x27;</span>, <span class="hljs-string">&#x27;Db&#x27;</span>, <span class="hljs-string">&#x27;Dg&#x27;</span>, <span class="hljs-string">&#x27;Dk&#x27;</span>, <span class="hljs-string">&#x27;^b&#x27;</span>, <span class="hljs-string">&#x27;+b&#x27;</span>, <span class="hljs-string">&#x27;sb&#x27;</span>, <span class="hljs-string">&#x27;db&#x27;</span>, <span class="hljs-string">&#x27;&lt;b&#x27;</span>, <span class="hljs-string">&#x27;pb&#x27;</span>] <span class="hljs-comment">#中心的颜色</span><br>    <span class="hljs-comment"># draw the centroids</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        plt.plot(centroids[i, <span class="hljs-number">0</span>], centroids[i, <span class="hljs-number">1</span>], mark[i], markersize = <span class="hljs-number">12</span>) <span class="hljs-comment">#画出中心点</span><br>    plt.show() <span class="hljs-comment">#显示图片</span><br></code></pre></td></tr></table></figure><ul><li>&quot;.txt&quot;文件的读取：<br />f=open(file_path) #其中 f 叫做文件句柄，file_path 为文件所在的路径。<br />f.readlines()函数用来读取文件中的全部内容，返回值为一个列表，列表中的每个元素为每行对应的内容。<br />f.close()用来关闭所打开的文件。</li><li>.strip()方法用于移除字符串头尾指定的字符（默认为空格或换行符）。</li><li>.split(str)方法通过指定分隔符对字符串进行切片，其中参数 str 为分隔符，返回值为<br />一个列表。</li><li>.append(obj)方法用于在列表末尾添加 obj。</li></ul><pre class="highlight"><code class="python">  <span class="hljs-comment">## step 1: 载入待聚类数据</span><span class="hljs-keyword">print</span> (<span class="hljs-string">"step 1: load data..."</span> )dataSet = [] <span class="hljs-comment">#列表，用来表示，列表中的每个元素也是一个二维的列表；这个二维列表就是一个样本，样本中包含有我们的属性值和类别号。</span><span class="hljs-comment">#与我们所熟悉的矩阵类似，最终我们将获得 N*2 的矩阵，每行元素构成了我们的训练样本的属性值和类别号</span>fileIn = open(<span class="hljs-string">"testdata.txt"</span>) <span class="hljs-comment">#"D:/testdata.txt"为数据文件所在位置的绝对路径。</span><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> fileIn.readlines(): <span class="hljs-comment">#依次遍历每一行</span>    temp=[] <span class="hljs-comment">#定义一个缓存列表</span>    lineArr = line.strip().split(<span class="hljs-string">'\t'</span>) <span class="hljs-comment">#line.strip()把末尾的'\n'去掉，.split('\t')表示以'\t'为分隔符将字符串切片。</span>    temp.append(float(lineArr[<span class="hljs-number">0</span>])) <span class="hljs-comment">#float(a)表示将 a 转化为 float 类型。</span>    temp.append(float(lineArr[<span class="hljs-number">1</span>]))    dataSet.append(temp) <span class="hljs-comment">#向 dataSet 列表中添加元素。</span>fileIn.close() <span class="hljs-comment">#关闭刚刚打开的 testdata.txt 文件。</span><span class="hljs-comment">## step 2: 聚类中... </span><span class="hljs-keyword">print</span> (<span class="hljs-string">"step 2: clustering..."</span> )dataSet = mat(dataSet) <span class="hljs-comment">#mat()函数是 Numpy 中的库函数，将数组转化为矩阵</span>k = <span class="hljs-number">4</span>centroids, clusterAssment = kmeans(dataSet, k) <span class="hljs-comment">#调用 KMeans 文件中定义的 kmeans 方法</span><span class="hljs-comment">## step 3: 画图展示结果</span><span class="hljs-keyword">print</span> (<span class="hljs-string">"step 3: show the result..."</span> )showCluster(dataSet, k, centroids, clusterAssment)</code></pre><p>实验结果如下<br /><img src="https://s1.imagehub.cc/images/2022/08/30/output.png" alt="g10" /><br /><strong>原理</strong><br />聚类属于非监督学习，K均值聚类是最基础常用的聚类算法。它的基本思想是，通过迭代寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的损失函数最小。<br />KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少损失函数；再固定每个样本的类别，调整中心点继续减小损失函数。两个过程交替循环，损失函数单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</p>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一篇Blog</title>
    <link href="/2022/08/29/%E7%AC%AC%E4%B8%80%E7%AF%87Blog/"/>
    <url>/2022/08/29/%E7%AC%AC%E4%B8%80%E7%AF%87Blog/</url>
    
    <content type="html"><![CDATA[<p>简要记录github+hexo搭建个人博客的步骤</p> <span id="more"></span><h1 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h1><ul><li><a href="#%E5%AE%89%E8%A3%85hexo">安装Hexo</a></li><li><a href="#%E4%B8%8B%E8%BD%BDgit">下载Git</a></li><li><a href="#git%E7%BB%91%E5%AE%9Agithub">Git绑定Github</a><ul><li><a href="#%E7%BB%91%E5%AE%9Agithub">绑定Github</a></li><li><a href="#%E6%8F%90%E4%BA%A4%E6%96%87%E4%BB%B6%E6%9C%AC%E5%9C%B0%E6%B2%A1%E6%9C%89git%E4%BB%93%E5%BA%93">提交文件(本地没有git仓库)</a></li></ul></li><li><a href="#%E5%AE%89%E8%A3%85node.js">安装node.js</a></li><li><a href="#%E5%AE%89%E8%A3%85Hexo">安装Hexo</a></li></ul><hr /><h2 id="下载git"><a class="markdownIt-Anchor" href="#下载git"></a> 下载Git</h2><p><a href="https://git-scm.com/">Git官网</a></p><h2 id="git绑定github"><a class="markdownIt-Anchor" href="#git绑定github"></a> Git绑定Github</h2><h3 id="绑定github"><a class="markdownIt-Anchor" href="#绑定github"></a> 绑定Github</h3><p>我们要用git上传文件到GitHub首先得利用SSH<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>登录远程主机，而登录方式有两种：一种是口令登录；另一种是公钥登录。口令登录每次都要输入密码十分麻烦，而公钥登录就省去了输入密码的步骤，所以我们选择公钥授权。首先我们得在 GitHub 上添加 SSH key 配置，要想生成SSH key，就要先安装 SSH，不过我们安装了 Git Bash，其应该自带了 SSH。</p><p>然后，输入 ssh-keygen -t rsa 命令（注意空格），表示我们指定 RSA 算法生成密钥，然后敲四次回车键，之后就就会生成两个文件，分别为秘钥 id_rsa 和公钥 id_rsa.pub.。<br />接下来我们要做的事情就是把公钥 id_rsa.pub 的内容添加到 GitHub。复制公钥 id_rsa.pub 文件里的内容:<br />接下来进入我们的 GitHub 主页，先点击右上角，再点击 settings ,点击 SSH and GPG keys，再点击 New SSH key,将复制的公钥 id_rsa.pub 的内容粘贴到 key 内，再点击 Add SSH key。</p><blockquote><p>git中的复制粘贴不是 Ctrl+C 和 Ctrl+V，而是 Ctrl+insert 和Shift+insert。</p></blockquote><h3 id="提交文件本地没有git仓库"><a class="markdownIt-Anchor" href="#提交文件本地没有git仓库"></a> 提交文件(本地没有git仓库)</h3><p>进入GitHub个人主页，点击进入新建的 text 项目，点击 Clone or download，再复制地址，然后进入我们准备存储 Git 仓库的目录（在git仓库这个文件下右键打开Git Bash），接下来，输入 git clone <a href="https://github.com/yourname/text.git">https://github.com/yourname/text.git</a> ，将远程仓库 clone 到本地。<br />现在我们在git仓库创建一个 text.txt 测试文件，从此目录进入 Git Bash，输入 git status 命令查看仓库状态。text 已经是一个 Git 仓库了，而我们刚刚创建的文件 text.txt 没有被追踪，也就是没有提交到本地仓库。现在我们使用 git add 命令将文件添加到了「临时缓冲区」，再用 git commit -m “提交信息” 将其提交到本地仓库。输入 git log 命令查看仓库提交日志。现在输入 git push origin main 命令，将本地仓库提交到远程仓库，这时Github就有了text文件。</p><h3 id="安装nodejs"><a class="markdownIt-Anchor" href="#安装nodejs"></a> 安装node.js</h3><p><a href="https://nodejs.org/en/">node.js官网</a><br />安装完成可以用打开cmd检验一下是否安装成功，用 node -v 和 npm -v 命令检查版本<br /><strong>设置npm在安装全局模块时的路径和环境变量：</strong><br />因为如果不设置的话，安装模块的时候就会把模块装到C盘，占用C盘的空间，并且有可能安装好hexo后却无法使用，所以我们需要设置一下：<br />在 nodejs 文件夹中新建两个空文件夹 node_cache、node_global，打开cmd，输入如下两个命令：</p><blockquote><p>npm config set prefix “D:\nodejs\node_global”<br />n&gt;pm config set cache “D:\nodejs\node_cache”</p></blockquote><p>然后<strong>设置环境变量</strong>：在系统变量中新建一个变量名为“NODE_PATH”，值为:</p><blockquote><p>D:\nodejs\node_modules</p></blockquote><p>然后编辑用户变量里的Path，将相应npm的路径改为：</p><blockquote><p>D:\nodejs\node_global</p></blockquote><h3 id="安装hexo"><a class="markdownIt-Anchor" href="#安装hexo"></a> 安装Hexo</h3><p>Hexo就是我们的个人博客网站的框架，在安装之前，我们要先在GitHub上创立一个仓库，名称为&quot;<a href="http://yourname.github.io">yourname.github.io</a>&quot;(<strong>此处yourname必须和你github用户名相同</strong>)，访问权限选择Public。<br />接下来就是安装Hexo，首先在D盘建立一个文件夹 Blog，点开 Blog 文件夹，鼠标右键打开 Git Bush Here，输入npm命令安装Hexo：</p><blockquote><p>npm install -g hexo-cli</p></blockquote><p>安装完成后，输入 hexo init 命令初始化博客(可能会失败，多试几次)，然后输入 hexo g 静态部署，这时网页已经部署完成，输入 hexo s 命令可以查看。<br />现在回到我们的 Blog 文件夹，用笔记本打开 _config.yml 文件，下滑到文件底部，填上如下内容：</p><blockquote><p>deploy:<br />type: git<br />repository: <a href="https://github.com/yourname/yourname.github.io.git">https://github.com/yourname/yourname.github.io.git</a>  #你的仓库地址<br />branch: main</p></blockquote><p>然后回到 Blog 文件夹中，打开 Git Bash，安装Git部署插件，输入命令:</p><blockquote><p>npm install hexo-deployer-git --save</p></blockquote><p>然后分别输入以下三条命令：</p><blockquote><p>hexo clean   #清除缓存文件 db.json 和已生成的静态文件 public<br />hexo g       #生成网站静态文件到默认设置的 public 文件夹(hexo generate 的缩写)<br />hexo d       #自动生成网站静态文件，并部署到设定的仓库(hexo deploy 的缩写)</p></blockquote><p>(这三条命令在更新博客时也会用到)<br />完成以后，打开浏览器，输入 <a href="https://yourname.github.io">https://yourname.github.io</a> 就可以打开你的网页了</p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>SSH（安全外壳协议，Secure Shell 的缩写）是建立在应用层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议，利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。简单来说，SSH就是保障你的账户安全，将你的数据加密压缩，不仅防止其他人截获你的数据，还能加快传输速度。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    
    <tags>
      
      <tag>搭建个人网页</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
